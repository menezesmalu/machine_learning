{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTpAG3UCd33h"
   },
   "source": [
    "https://docs.google.com/forms/d/e/1FAIpQLSdI6cWyyHCBkn2h0lUXvZM9iGNX3y1QMRbKT0iSVsrm8Qhx_w/viewform?hr_submission=ChcIrpDc8gMSDwi72JqF0wgSBgiGjdbHJxAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jjcWEd14d33o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import urllib.request\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8BBhXWvd33p"
   },
   "source": [
    "# Preparação de dados\n",
    "\n",
    "* extração do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j9G9ZvGHE2lq"
   },
   "outputs": [],
   "source": [
    "url = 'http://promise.site.uottawa.ca/SERepository/datasets/kc1.arff'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data, meta = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "kc1 = pd.DataFrame(data)\n",
    "kc1 = kc1.sample(frac=1, random_state=20)\n",
    "kc1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLU1pzw_d33r"
   },
   "source": [
    "# Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2gnGwQ7Hd33r"
   },
   "outputs": [],
   "source": [
    "def  euclidian_distance(x1, x2):\n",
    "    arr = []\n",
    "    for i in range(len(x1)-1):\n",
    "        arr.append((x1[i] - x2[i])** 2)\n",
    "    return np.sqrt(np.sum(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_labels = []\n",
    "        for _, row in X.iterrows():\n",
    "            predicted_labels.append(self.predict_func(row))\n",
    "\n",
    "        return np.array(predicted_labels)\n",
    "        \n",
    "    def predict_func(self, x):\n",
    "        distances = []\n",
    "        for _, row in self.X_train.iterrows():\n",
    "            distances.append(euclidian_distance(x, row))\n",
    "          \n",
    "        k_indices = np.argsort(distances)[:self.k]        \n",
    "        k_nearest_labels = [self.y_train.iloc[i] for i in k_indices]\n",
    "\n",
    "        unique, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "        predicted = unique[counts.argmax()]\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_class(df):\n",
    "    Y = df[\"defects\"]\n",
    "    X = df.drop(columns=[\"defects\"]) \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_scaled = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    Y = Y.apply(str).str.replace(\"b|'\", '')\n",
    "\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _attr_class(df):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for row in df:\n",
    "        x.append(row[:-1])\n",
    "        y.append(row[-1])\n",
    "\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LVQ1:   \n",
    "    \n",
    "    def __init__(self, n_prototypes):\n",
    "        self.n_prototypes  = n_prototypes\n",
    "        self._epochs        = 1\n",
    "        self._lrate        = 0.25\n",
    "\n",
    "    \n",
    "    def random_prototype(self, train):\n",
    "        n_records  = train.shape[0]\n",
    "        n_features = train.shape[1]\n",
    "        prototypes  = []\n",
    "        records    = []\n",
    "        random.seed(10)\n",
    "        for i in range(self.n_prototypes):\n",
    "            records.append(random.randint(0, n_records-1))\n",
    "        \n",
    "        for r in records:\n",
    "            prototype = [train.iloc[r][i] for i in range(n_features)]\n",
    "            prototypes.append(prototype)\n",
    "        \n",
    "        return prototypes, records\n",
    "    \n",
    "\n",
    "    def trainPrototypes(self,train):\n",
    "        prototypes = []\n",
    "        records = []\n",
    "        aux = train\n",
    "        for i in range(self.n_prototypes):\n",
    "            prototypes, records = self.random_prototype(train)\n",
    "        for i in records:\n",
    "            aux = aux.drop(aux.loc[aux.index==i].index)\n",
    "        aux = aux.reset_index(drop=True)\n",
    "        \n",
    "        x_train, y_train = attr_class(aux)\n",
    "        x_proto, y_proto = _attr_class(prototypes)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(x_train, y_train)\n",
    "        for epoch in range(self._epochs):            \n",
    "            rate  = self._lrate * (1.0 - (epoch / float(self._epochs)))\n",
    "            predicted_classes = knn.predict(x_proto) \n",
    "            real_instances = knn.kneighbors(X=x_proto, n_neighbors=1, return_distance=False)\n",
    "            for idx in range(len(x_proto)):\n",
    "                prototype = x_proto[idx] # prototipo (ta sendo alterado o valor)\n",
    "                proto_class = y_proto[idx] #classe do prototipo \n",
    "                \n",
    "                predicted_class = predicted_classes[idx] #classe prevista pra esse prototipo \n",
    "                real_instance_index = real_instances[idx][0] #indice instancia real daquele prototipo \n",
    "                real_instance = x_train.iloc[real_instance_index] # instancia real\n",
    "                \n",
    "                for p in range(len(prototype)): #passa por cada coluna do prototipo\n",
    "                    proto_val = prototype[p]\n",
    "                    real_val  = real_instance[p]\n",
    "                    error = rate * (real_val - proto_val)\n",
    "                    if proto_class == predicted_class:\n",
    "                        prototype[p] += error\n",
    "                    else:\n",
    "                        prototype[p] -= error\n",
    "\n",
    "       \n",
    "        return pd.DataFrame(prototypes, columns = train.columns)\n",
    "\n",
    "# lvq1 = LVQ1(10)\n",
    "# df  = lvq1.trainPrototypes(kc2)\n",
    "# df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ2_1:   \n",
    "    \n",
    "    def __init__(self, n_prototypes, window):\n",
    "        self.n_prototypes  = n_prototypes\n",
    "        self._epochs        = 10\n",
    "        self._lrate        = 0.25\n",
    "        self._window        = window\n",
    "\n",
    "    \n",
    "    def inside(self):\n",
    "        return (1.0 - self._window) / (1.0 + self._window)\n",
    "    \n",
    "    def window(self, d1, d2):\n",
    "        a  = d1/d2\n",
    "        b  = d2/d1\n",
    "        minimum = min(a,b)\n",
    "        return minimum > self.inside()\n",
    "    \n",
    "    def updatePrototypes(self, prototype, real, same_class, rate):\n",
    "        for idx in range(21):\n",
    "            proto_val = prototype[idx]\n",
    "            real_val  = real[idx]\n",
    "            error = rate * (real_val - proto_val)\n",
    "            if same_class:\n",
    "                prototype[idx] += error\n",
    "            else:\n",
    "                prototype[idx] -= error\n",
    "        return prototype\n",
    "    \n",
    "    def trainPrototypes(self,train, df_prototypes):\n",
    "        x_train, y_train = attr_class(train)\n",
    "        x_proto, y_proto = attr_class(df_prototypes)\n",
    "        knn = KNeighborsClassifier(n_neighbors=2)\n",
    "        knn.fit(x_proto, y_proto)\n",
    "        for epoch in range(self._epochs):\n",
    "            rate  = self._lrate * (1.0 - (epoch / float(self._epochs)))\n",
    "            x_neighbors = knn.kneighbors(X=x_train, n_neighbors=2, return_distance=False)\n",
    "            for idx, _ in x_train.iterrows():\n",
    "                x_instance = x_train.iloc[idx]\n",
    "                x_class = y_train.iloc[idx]\n",
    "                \n",
    "                #mais próximo\n",
    "                n1_idx   = x_neighbors[idx][0]\n",
    "                n1       = x_proto.iloc[n1_idx]\n",
    "                n1       = n1[:21] ##tá adicionando o indice como uma coluna na iteração seguinte\n",
    "                n1_class = y_proto[n1_idx]\n",
    "                n1_dist  = euclidian_distance(n1, x_instance) \n",
    "                \n",
    "                #segundo mais próximo\n",
    "                n2_idx   = x_neighbors[idx][0]\n",
    "                n2       = x_proto.iloc[n2_idx]\n",
    "                n2       = n2[:21]\n",
    "                n2_class = y_proto[n2_idx]\n",
    "                n2_dist  = euclidian_distance(n2, x_instance)\n",
    "                \n",
    "                insideWindow = self.window(n1_dist, n2_dist)\n",
    "                if insideWindow or n1_class != n2_class:\n",
    "                    x_proto.iloc[n1_idx] = self.updatePrototypes(n1, x_instance, n1_class == x_class, rate)\n",
    "                    x_proto.iloc[n2_idx] = self.updatePrototypes(n2, x_instance, n2_class == x_class, rate)\n",
    "        prototypes = pd.concat([x_proto, y_proto], axis=1)\n",
    "        prototypes.columns = kc1.columns\n",
    "        return prototypes \n",
    "    \n",
    "# lvq2 = LVQ2_1(100, 0.25)\n",
    "# df2  = lvq2.trainPrototypes(kc2, df)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ3:   \n",
    "    \n",
    "    def __init__(self, n_prototypes, window):\n",
    "        self.n_prototypes  = n_prototypes\n",
    "        self._epochs       = 10\n",
    "        self._lrate        = 0.25\n",
    "        self._window       = window\n",
    "        \n",
    "        \n",
    "    def getNeighborPrototype(self, prototypes, row):\n",
    "        distances  = []\n",
    "        final_dist = []\n",
    "        for _,proto in prototypes.iterrows():\n",
    "            dist = euclidian_distance(proto, row)\n",
    "            distances.append((proto, dist))\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        final_dist.append(distances[1])\n",
    "        final_dist.append(distances[2])\n",
    "        return final_dist\n",
    "    \n",
    "    def inside(self):\n",
    "        return (1.0 - self._window) / (1.0 + self._window)\n",
    "    \n",
    "    def window(self, d1, d2):\n",
    "        a  = d1/d2\n",
    "        b  = d2/d1\n",
    "        minimum = min(a,b)\n",
    "        return minimum > self.inside()\n",
    "    \n",
    "    def updatePrototypes(self, prototype, real, same_class, rate):\n",
    "        for idx in range(21):\n",
    "            proto_val = prototype[idx]\n",
    "            real_val  = real[idx]\n",
    "            error = rate * (real_val - proto_val)\n",
    "            if same_class:\n",
    "                prototype[idx] += error\n",
    "            else:\n",
    "                prototype[idx] -= error\n",
    "        return prototype\n",
    "    \n",
    "    def trainPrototypes(self,train, df_prototypes):\n",
    "        x_train, y_train = attr_class(train)\n",
    "        x_proto, y_proto = attr_class(df_prototypes)\n",
    "        knn = KNeighborsClassifier(n_neighbors=2)\n",
    "        knn.fit(x_proto, y_proto)        \n",
    "        for epoch in range(self._epochs):\n",
    "            rate = self._lrate * (1.0 - (epoch / float(self._epochs)))\n",
    "            x_neighbors = knn.kneighbors(X=x_train, n_neighbors=2, return_distance=False)\n",
    "            for idx, _ in x_train.iterrows():\n",
    "                x_instance = x_train.iloc[idx]\n",
    "                x_class = y_train.iloc[idx]\n",
    "\n",
    "                #mais próximo\n",
    "                n1_idx   = x_neighbors[idx][0]\n",
    "                n1       = x_proto.iloc[n1_idx]\n",
    "                n1       = n1[:21] ##tá adicionando o indice como uma coluna na iteração seguinte\n",
    "                n1_class = y_proto[n1_idx]\n",
    "                n1_dist  = euclidian_distance(n1, x_instance) \n",
    "\n",
    "                #segundo mais próximo\n",
    "                n2_idx   = x_neighbors[idx][0]\n",
    "                n2       = x_proto.iloc[n2_idx]\n",
    "                n2       = n2[:21]\n",
    "                n2_class = y_proto[n2_idx]\n",
    "                n2_dist  = euclidian_distance(n2, x_instance)\n",
    "\n",
    "                insideWindow = self.window(n1_dist, n2_dist)\n",
    "                if insideWindow:\n",
    "                    if n1_class != n2_class:\n",
    "                        x_proto.iloc[n1_idx] = self.updatePrototypes(n1, x_instance, n1_class == x_class, rate)\n",
    "                        x_proto.iloc[n2_idx] = self.updatePrototypes(n2, x_instance, n2_class == x_class, rate)\n",
    "                    else:\n",
    "                        x_proto.iloc[n1_idx] = self.updatePrototypes(n1, x_instance, True, rate)\n",
    "                        x_proto.iloc[n2_idx] = self.updatePrototypes(n2, x_instance, True, rate)\n",
    "\n",
    "        prototypes = pd.concat([x_proto, y_proto], axis=1)\n",
    "        prototypes.columns = kc1.columns\n",
    "        return prototypes\n",
    "    \n",
    "# lvq3 = LVQ3(10, 0.3)\n",
    "# res  = lvq3.trainPrototypes(kc1, df)\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lvq3 = LVQ3(10, 0.3, 0.5)\n",
    "# res  = lvq3.trainPrototypes(df)\n",
    "# df3 = pd.DataFrame(res, columns = kc2.columns)\n",
    "# df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQe1qPw7Nea"
   },
   "source": [
    "## KNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10): simples 96.25491101079578 lvq1 84.4941518163704 lvq2 84.92080467404396 lvq3 84.35185914827031\n",
      "(3, 10): simples 90.61149823822765 lvq1 84.54165775461267 lvq2 84.54165775461267 lvq3 84.54165775461267\n",
      "(1, 50): simples 96.25491101079578 lvq1 82.7863020792291 lvq2 42.56745955803717 lvq3 82.40771802636466\n",
      "(3, 50): simples 90.61149823822765 lvq1 84.49426438968378 lvq2 71.66698562438788 lvq3 84.44664587812812\n",
      "(1, 100): simples 96.25491101079578 lvq1 79.5162724724477 lvq2 43.23085409372854 lvq3 81.0336481633664\n"
     ]
    }
   ],
   "source": [
    "def run(df, title):\n",
    "    kf = KFold(n_splits=5)\n",
    "    results = []\n",
    "    n_proto = [10, 50, 100, 200]\n",
    "    for n in n_proto:\n",
    "        for k in [1,3]:\n",
    "            accuracies_simples = []\n",
    "            accuracies_lvq1   = []\n",
    "            accuracies_lvq2   = []\n",
    "            accuracies_lvq3   = []\n",
    "            index = 0\n",
    "            for train, test in kf.split(df):\n",
    "                #separação conj de teste atributos e classe\n",
    "                attr, df_class = attr_class(df)\n",
    "\n",
    "                # KNN com conjunto normal\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(attr, df_class)\n",
    "                predictions_simples = knn.predict(attr.iloc[test])\n",
    "                acc_simples = (np.sum(predictions_simples == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_simples.append(acc_simples)\n",
    "                \n",
    "                #definição do dataset de LVQ1\n",
    "                lvq1 = LVQ1(n)\n",
    "                aux = df.iloc[train]\n",
    "                aux.reset_index(drop=True, inplace=True)\n",
    "                res  = lvq1.trainPrototypes(aux)\n",
    "                lvq1_df  = pd.DataFrame(res, columns = df.columns)\n",
    "                \n",
    "                #separação do treinamento LVQ1 atributos e classe\n",
    "                X, Y = attr_class(lvq1_df)\n",
    "                \n",
    "                #KNN com conjunto do LVQ1\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_lvq1 = knn.predict(attr.iloc[test])\n",
    "                acc_lvq1 = (np.sum(predictions_lvq1 == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_lvq1.append(acc_lvq1)\n",
    "                \n",
    "                #definição do dataset de LVQ2.1\n",
    "                lvq2 = LVQ2_1(n, 0.25)\n",
    "                res  = lvq2.trainPrototypes(aux,lvq1_df)\n",
    "                lvq2_df  = pd.DataFrame(res, columns = df.columns)\n",
    "                \n",
    "                #separação do treinamento LVQ2.1 atributos e classe\n",
    "                X, Y = attr_class(lvq2_df)\n",
    "                \n",
    "                #KNN com conjunto do LVQ2.1\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_lvq2 = knn.predict(attr.iloc[test])\n",
    "                acc_lvq2 = (np.sum(predictions_lvq2 == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_lvq2.append(acc_lvq2)\n",
    "                \n",
    "                #definição do dataset de LVQ3\n",
    "                lvq3 = LVQ3(n, 0.5)\n",
    "                res  = lvq3.trainPrototypes(aux,lvq1_df)\n",
    "                lvq3_df  = pd.DataFrame(res, columns = df.columns)\n",
    "                \n",
    "                #separação do treinamento LVQ3 atributos e classe\n",
    "                X, Y = attr_class(lvq3_df)\n",
    "                \n",
    "                #KNN com conjunto do LVQ3\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_lvq3 = knn.predict(attr.iloc[test])\n",
    "                acc_lvq3 = (np.sum(predictions_lvq3 == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_lvq3.append(acc_lvq3)\n",
    "            \n",
    "            print(\"({}, {}): simples {} lvq1 {} lvq2 {} lvq3 {}\".format(k, n, np.mean(accuracies_simples),np.mean(accuracies_lvq1),np.mean(accuracies_lvq2), np.mean(accuracies_lvq3)))\n",
    "            temp = {\n",
    "                'dataframe': title,\n",
    "                '(k, prototypes)':(k, n),\n",
    "                'acc_simples': np.mean(accuracies_simples),\n",
    "                'std_simples': np.std(accuracies_simples),\n",
    "                'acc_LVQ1'   : np.mean(accuracies_lvq1),\n",
    "                'std_LVQ1'   : np.std(accuracies_lvq1),\n",
    "                'acc_LVQ2.1' : np.mean(accuracies_lvq2),\n",
    "                'std_LVQ2.1' : np.std(accuracies_lvq2),\n",
    "                'acc_LVQ3'   : np.mean(accuracies_lvq3),\n",
    "                'std_LVQ3'   : np.std(accuracies_lvq3),\n",
    "            }\n",
    "            results.append(temp)\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "df = run(kc1, 'KC1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "menos protótipos > resultado mto ruim > desbalanço do conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "curva roc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _printComparative(df):\n",
    "    \n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"Scatter\"}]],\n",
    "    subplot_titles=(\"Acurácia\"))\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_simples'], name='Simples', mode = 'lines+markers'), col = 1, row = 1) \n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_LVQ1'], name='LVQ1', mode = 'lines+markers'), col = 1, row = 1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_LVQ2.1'], name='LVQ2.1', mode = 'lines+markers'), col = 1, row = 1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_LVQ3'], name='LVQ3', mode = 'lines+markers'), col = 1, row = 1)\n",
    "    \n",
    "    fig.update_layout(height=1000, width=1000)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _printComparative(df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "atv-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
