{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTpAG3UCd33h"
   },
   "source": [
    "https://docs.google.com/forms/d/e/1FAIpQLSdI6cWyyHCBkn2h0lUXvZM9iGNX3y1QMRbKT0iSVsrm8Qhx_w/viewform?hr_submission=ChcIrpDc8gMSDwi72JqF0wgSBgiGjdbHJxAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jjcWEd14d33o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import urllib.request\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "from random import randrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8BBhXWvd33p"
   },
   "source": [
    "# Preparação de dados\n",
    "\n",
    "* extração do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9G9ZvGHE2lq"
   },
   "outputs": [],
   "source": [
    "url = 'http://promise.site.uottawa.ca/SERepository/datasets/kc1.arff'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data, meta = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "kc1 = pd.DataFrame(data)\n",
    "kc1 = kc1.sample(frac=1, random_state=20)\n",
    "kc1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRL-rZuTd33q"
   },
   "outputs": [],
   "source": [
    "url = 'http://promise.site.uottawa.ca/SERepository/datasets/kc2.arff'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data, meta = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "kc2 = pd.DataFrame(data)\n",
    "kc2 = kc2.sample(frac=1, random_state=20)\n",
    "kc2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLU1pzw_d33r"
   },
   "source": [
    "# Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gnGwQ7Hd33r"
   },
   "outputs": [],
   "source": [
    "def  euclidian_distance(x1, x2):\n",
    "    arr = []\n",
    "    for i in range(len(x1)-1):\n",
    "        arr.append((x1[i] - x2[i])** 2)\n",
    "    return np.sqrt(np.sum(arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Vector Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ1:   \n",
    "    \n",
    "    def __init__(self, n_prototypes):\n",
    "        self.n_prototypes  = n_prototypes\n",
    "        self.epochs        = 10\n",
    "        self.l_rate        = 0.25\n",
    "        \n",
    "    def getNeighborPrototype(self, prototypes, row):\n",
    "        distances = []\n",
    "        for proto in prototypes:\n",
    "            dist = euclidian_distance(proto, row)\n",
    "            distances.append((proto, dist))\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        return distances[0][0]\n",
    "    \n",
    "    def random_prototype(self, train):\n",
    "        n_records  = train.shape[0]\n",
    "        n_features = train.shape[1]\n",
    "        prototype = []\n",
    "        prototype = [train.iloc[randrange(n_records)][i] for i in range(n_features)]\n",
    "        return prototype            \n",
    "    \n",
    "    def trainPrototypes(self,train):\n",
    "        prototypes = [self.random_prototype(train) for i in range(self.n_prototypes)]\n",
    "        for epoch in range(self.epochs):\n",
    "            rate = self.l_rate * (1 - (epoch/float(self.epochs) ) )\n",
    "            for _, row in train.iterrows():\n",
    "                n_proto = self.getNeighborPrototype(prototypes, row)\n",
    "                for i in range(len(row) -1):\n",
    "                    error = (row[i]) - (n_proto[i])\n",
    "                    if(row[-1] == n_proto[-1]):\n",
    "                        n_proto[i] += rate * error\n",
    "                    else:\n",
    "                        n_proto[i] -= rate * error\n",
    "        return prototypes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvq1 = LVQ1(10)\n",
    "res  = lvq1.trainPrototypes(kc2)\n",
    "\n",
    "df = pd.DataFrame(res, columns = kc2.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ2_1:   \n",
    "    \n",
    "    def __init__(self, n_prototypes, window):\n",
    "        self.n_prototypes  = n_prototypes\n",
    "        self._epochs        = 10\n",
    "        self._lrate        = 0.25\n",
    "        self._window        = window\n",
    "        \n",
    "    def getNeighborPrototype(self, prototypes, row):\n",
    "        distances  = []\n",
    "        final_dist = []\n",
    "        for _,proto in prototypes.iterrows():\n",
    "            dist = euclidian_distance(proto, row)\n",
    "            distances.append((proto, dist))\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        final_dist.append(distances[1])\n",
    "        final_dist.append(distances[2])\n",
    "        return final_dist\n",
    "    \n",
    "    def inside(self):\n",
    "        return (1.0 - self._window) / (1.0 + self._window)\n",
    "    \n",
    "    def window(self, neighbors):\n",
    "        di = neighbors[0][1]\n",
    "        dj = neighbors[1][1]\n",
    "        a  = di/dj\n",
    "        b  = dj/di\n",
    "        minimum = min(a,b)\n",
    "        return minimum > self.inside()\n",
    "    \n",
    "    def trainPrototypes(self,train):\n",
    "        prototypes = copy.deepcopy(train)\n",
    "        for epoch in range(self._epochs):\n",
    "            rate = self._lrate * (1 - (epoch / float(self._epochs) ) )\n",
    "            for _, row in train.iterrows():\n",
    "                n_proto = self.getNeighborPrototype(prototypes, row)\n",
    "                \n",
    "                n1 = n_proto[0][0]\n",
    "                n2 = n_proto[1][0]\n",
    "\n",
    "                isWindow = self.window(n_proto)\n",
    "                if isWindow or n1[-1] != n2[-1]:\n",
    "                    for i in range(len(row) - 2):\n",
    "                        error = (row[i]) - (n1[i])\n",
    "                        if n1[-1] == row[-1]:\n",
    "                            n1[i] += rate * error\n",
    "                        else:\n",
    "                            n1[i] -= rate * error\n",
    "\n",
    "\n",
    "        return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvq2 = LVQ2_1(10, 0.25)\n",
    "res  = lvq2.trainPrototypes(test)\n",
    "df = pd.DataFrame(res, columns = kc2.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVQ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQe1qPw7Nea"
   },
   "source": [
    "## KNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_labels = []\n",
    "        for _, row in X.iterrows():\n",
    "            predicted_labels.append(self.predict_func(row))\n",
    "\n",
    "        return np.array(predicted_labels)\n",
    "        \n",
    "    def predict_func(self, x):\n",
    "        distances = []\n",
    "        for _, row in self.X_train.iterrows():\n",
    "            distances.append(euclidian_distance(x, row))\n",
    "          \n",
    "        k_indices = np.argsort(distances)[:self.k]        \n",
    "        k_nearest_labels = [self.y_train.iloc[i] for i in k_indices]\n",
    "\n",
    "        unique, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "        predicted = unique[counts.argmax()]\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_class(df, _class):\n",
    "    Y = df[_class]\n",
    "    X = df.drop(columns=[_class]) \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_scaled = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, _class, title):\n",
    "    kf = KFold(n_splits=5)\n",
    "    results = []\n",
    "    n_proto = [10, 25, 50, 100, 200]\n",
    "    for n in n_proto:\n",
    "        for k in [1,3]:\n",
    "            accuracies_simples = []\n",
    "            accuracies_lvq1   = []\n",
    "            accuracies_lvq2   = []\n",
    "            for train, test in kf.split(df):\n",
    "                #separação conj de teste atributos e classe\n",
    "                X, Y = attr_class(df, _class)\n",
    "\n",
    "                # KNN com conjunto normal\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_simples = knn.predict(attr.iloc[test])\n",
    "                acc_simples = (np.sum(predictions_simples == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_simples.append(acc_simples)\n",
    "                \n",
    "                #definição do dataset de LVQ1\n",
    "                lvq1 = LVQ1(n)\n",
    "                res  = lvq1.trainPrototypes(df.iloc[train])\n",
    "                lvq1_df  = pd.DataFrame(res, columns = df.columns)\n",
    "                \n",
    "                #separação do treinamento LVQ1 atributos e classe\n",
    "                X, Y = attr_class(lvq1_df, _class)\n",
    "                \n",
    "                #KNN com conjunto do LVQ1\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_lvq1 = knn.predict(attr.iloc[test])\n",
    "                acc_lvq1 = (np.sum(predictions_lvq1 == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_lvq1.append(acc_lvq1)\n",
    "                \n",
    "                #definição do dataset de LVQ2.1\n",
    "                lvq2 = LVQ2_1(n, 0.25)\n",
    "                res  = lvq2.trainPrototypes(lvq1_df.iloc[train])\n",
    "                lvq2_df  = pd.DataFrame(res, columns = df.columns)\n",
    "                \n",
    "                #separação do treinamento LVQ2.1 atributos e classe\n",
    "                X, Y = attr_class(lvq2_df, _class)\n",
    "                \n",
    "                #KNN com conjunto do LVQ2.1\n",
    "                knn  = KNN(k)\n",
    "                knn.fit(X, Y)\n",
    "                predictions_lvq2 = knn.predict(attr.iloc[test])\n",
    "                acc_lvq2 = (np.sum(predictions_lvq2 == df_class.iloc[test]) / len(test)) * 100\n",
    "                accuracies_lvq2.append(acc_lvq2)\n",
    "\n",
    "\n",
    "            temp = {\n",
    "                'dataframe': title,\n",
    "                '(k, prototypes)':(k, n),\n",
    "                'acc_simples': np.mean(accuracies_simples),\n",
    "                'std_simples': np.std(accuracies_simples),\n",
    "                'acc_LVQ1': np.mean(accuracies_lvq1),\n",
    "                'std_LVQ1': np.std(accuracies_lvq1),\n",
    "                'acc_LVQ2.1': np.mean(accuracies_lvq2),\n",
    "                'std_LVQ2.1': np.std(accuracies_lvq2),\n",
    "            }\n",
    "            results.append(temp)\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "df = run(kc2, 'problems', 'KC2')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _printComparative(df):\n",
    "    \n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"Scatter\"}]],\n",
    "    subplot_titles=(\"Acurácia\"))\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_simples'], name='Simples', mode = 'lines+markers'), col = 1, row = 1) \n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_LVQ1'], name='LVQ1', mode = 'lines+markers'), col = 1, row = 1)\n",
    "    fig.add_trace(go.Scatter(x=df.index, y = df['acc_LVQ2.1'], name='LVQ2.1', mode = 'lines+markers'), col = 1, row = 1)\n",
    "    \n",
    "    fig.update_layout(height=1000, width=1000)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _printComparative(df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "atv-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
